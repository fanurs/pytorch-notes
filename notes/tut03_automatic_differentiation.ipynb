{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3M4KzVVUhOYB/Yuh2/8cx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fanurs/pytorch-notes/blob/main/notes/tut03_automatic_differentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic differentiation"
      ],
      "metadata": {
        "id": "dxzQ6EMfx0Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are at least three ways to evaluate the derivative of a function: symbolic differentiation, numerical differentiation, and automatic differentiation.\n",
        "\n",
        "Symbolic differentiation is what we usually first learned in calculus. However, for most applications, it is difficult for computer to automate this process.\n",
        "\n",
        "Numerical differentiation uses the method of finite differences to approximate a derivative,\n",
        "$$ \\frac{df(x)}{dx} \\approx \\frac{f(x + \\delta x) - f(x)}{\\delta x} \\ . $$\n",
        "But this approach introduces round-off errors.\n",
        "\n",
        "Automatic differentiation (AD) exploits the fact that every function can be computed using a chain of arithmetic operations. Hence, using the chain rule, it is possible to evaluate the resulting derivative."
      ],
      "metadata": {
        "id": "7bNFu5rGx56w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AD is usually faster and numerically more stable."
      ],
      "metadata": {
        "id": "4fQNa7Kk0-Yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any machine learning algorithm is essentially some kind of optimization problem. This is why having a reliable way to compute a gradient is very useful. PyTorch offers an automatic differeniation package called [`torch.autograd`](https://pytorch.org/docs/stable/autograd.html) to handle these tasks."
      ],
      "metadata": {
        "id": "DTtKnF1Q1ykn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differentiating a single-variable function"
      ],
      "metadata": {
        "id": "-pEInF-u45C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch as th"
      ],
      "metadata": {
        "id": "qNkWEIcq5xnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the tensors"
      ],
      "metadata": {
        "id": "OuhHazm1_wya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by using PyTorch to solve a simple example. Given $g(x) = x^2$, evaluate\n",
        "$$ \\frac{d}{dx}g(x) $$\n",
        "over the domain $x\\in[-3, 3]$."
      ],
      "metadata": {
        "id": "Dvj5FG855Yww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = th.linspace(-3, 3, 301)\n",
        "y = x**2\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cRL_MsvX55La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far there is no differentiation involved. We are just plotting out the function $g(x) = x^2$ over the interval $x\\in[-3, 3]$ with 301-point sampling:\n",
        "$$ -3.00, -2.98, -2.96, \\ldots, 2.98, 3.00 \\ . $$\n",
        "\n",
        "To take the derivative, we would have to update an attribute, `torch.Tensor.requires_grad` to `True`. To propagate this attribute, we shall recompute `y` too."
      ],
      "metadata": {
        "id": "6WLbVENv6UtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad = True\n",
        "y = x**2\n",
        "x[0]"
      ],
      "metadata": {
        "id": "vwCJhC9R7Naa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that each entry of `x` is now a tensor that also contains the `grad_fn` property. This is where `autograd` will do its magic. But for now, it means if we try to plot by typing `plot.plot(x, y)`, an error will be raised. For `plot()` to work properly, we have to strip off the `grad_fn` part from the tensors. PyTorch provides us a `detach()` function for that."
      ],
      "metadata": {
        "id": "xBJKTWzO7hqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x.detach(), y.detach())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_hwca6gy9p0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking derivative as gradient"
      ],
      "metadata": {
        "id": "wooSxXWx_1CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So how can we actually take the derivative of $g(x)$?\n",
        "\n",
        "PyTorch's autograd can only compute the gradient,\n",
        "$$ \\nabla f(x_1, x_2, \\ldots, x_n) =\n",
        "\\begin{bmatrix}\n",
        "\\partial_1 f \\\\\n",
        "\\partial_2 f \\\\\n",
        "\\vdots \\\\\n",
        "\\partial_n f \\\\\n",
        "\\end{bmatrix} \\ .\n",
        "$$\n",
        "\n",
        "On the other hand, we have $g(x)$ evaluated at 301 discrete points,\n",
        "$$ x_k = -3 + 0.02 * (k - 1) $$\n",
        "for all $k = 1, 2, \\ldots, 301$. And we want to know its derivative $g'(x)$ at the same 301 discrete points,\n",
        "$$ g'(x_1), g'(x_2), \\ldots, g'(x_{301}) \\ . $$"
      ],
      "metadata": {
        "id": "E7YJc-nf_5o0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trick is to construct the sum\n",
        "$$ f(x_1, x_2, \\ldots, x_{301}) \\equiv g(x_1) + g(x_2) + \\cdots + g(x_{301}) \\ . $$\n",
        "Then the gradient of this sum would give us\n",
        "$$ \\nabla f(x_1, x_2, \\ldots, x_{301}) =\n",
        "\\begin{bmatrix}\n",
        "\\partial_1 f \\\\\n",
        "\\partial_2 f \\\\\n",
        "\\vdots \\\\\n",
        "\\partial_{301} f \\\\\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "g'(x_1) \\\\\n",
        "g'(x_2) \\\\\n",
        "\\vdots \\\\\n",
        "g'(x_{301}) \\\\\n",
        "\\end{bmatrix} \\ .\n",
        "$$\n",
        "\n",
        "In other words, instead of treating $g(x)$ as a single-variable function that depends on $x$, we may view $x_1, x_2, \\ldots, x_{301}$ as independent variables for the sum $f$. This is why constructing the tensors, we specified `requires_grad = True` for $x$, too."
      ],
      "metadata": {
        "id": "GGqkxvrlCvKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following the trick, we first compute the sum of all function values evaluated at the 301 discrete points:"
      ],
      "metadata": {
        "id": "hyk14JbeEBy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = y.sum()\n",
        "total"
      ],
      "metadata": {
        "id": "p42I9Rio93HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we calculate the gradient. The function for this is `torch.Tensor.backward()`. The reason for this weird name is because computation of a gradient in a neural network often happens in a process called \"backward propagation\"."
      ],
      "metadata": {
        "id": "Mg_VDTGTD6bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total.backward()"
      ],
      "metadata": {
        "id": "Zw81NN299wN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `backward()` function does not actually return anything. Instead, it traces back all the tensors that were used to build up `total` (i.e. `x` and `y`), and takes the partial derivatives with respective to each component that has a `grad_fn` property (traced computation history) to construct the gradient of `total`. The final result will be stored as `grad` attribute:"
      ],
      "metadata": {
        "id": "nFf5bt9iF3R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x.detach(), x.grad.detach())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G-T54C0D-E6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a line for $2x$, which is what we would expect for the derivative of $g(x) = x^2$."
      ],
      "metadata": {
        "id": "OVXqfADLGe1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us quickly apply all these steps to some more interesting function, $h(x) = \\sin(x^2)$:"
      ],
      "metadata": {
        "id": "hXFiYvG0G0HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = th.linspace(-3, 3, 100, requires_grad=True)\n",
        "y = th.sin(x**2)\n",
        "y.sum().backward()\n",
        "plt.plot(x.detach(), y.detach(), label='function')\n",
        "plt.plot(x.detach(), x.grad.detach(), label='derivative')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ff6DvOTZHPiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some remarks"
      ],
      "metadata": {
        "id": "Y8sjcpMPJ7rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AD is all about tracing back how a quantity is calculated from a chain of elementary arithmetic operations and applying chain rule. This is why PyTorch's autograd traces the computation history for all tensors that have set `requires_grad = True`. We can always turn off this tracing by setting `requires_grad = False`. However, this will immediately erase the computation history.\n",
        "\n",
        "To temporarily avoid tracing computation history, we can use `torch.no_grad()` in a context manager:"
      ],
      "metadata": {
        "id": "hxCWpw8hJ-HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = th.tensor([1.1, 1.2, 1.3], requires_grad=True)\n",
        "a = x**2\n",
        "with th.no_grad():\n",
        "    b = 2 * a\n",
        "c = 2 * a\n",
        "display(a, b, c)"
      ],
      "metadata": {
        "id": "cmdlkhf3KwjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "5ejCvL22x2yX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://en.wikipedia.org/wiki/Automatic_differentiation"
      ],
      "metadata": {
        "id": "pYs8s9Rkx39C"
      }
    }
  ]
}